{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption Preprocessing\n",
    "\n",
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow-3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from caption_utils import *\n",
    "\n",
    "train_fns_list, dev_fns_list, test_fns_list = load_split_lists()\n",
    "del train_fns_list[-1]\n",
    "del dev_fns_list[-1]\n",
    "del test_fns_list[-1]\n",
    "\n",
    "train_captions_raw, dev_captions_raw, test_captions_raw = get_caption_split()\n",
    "vocab = create_vocab(train_captions_raw)\n",
    "token2idx, idx2token = vocab_to_index(vocab)     \n",
    "captions_data = (train_captions_raw.copy(), dev_captions_raw.copy(), test_captions_raw.copy())\n",
    "train_captions, dev_captions, test_captions = process_captions(captions_data, token2idx)\n",
    "del train_captions['']\n",
    "del dev_captions['']\n",
    "del test_captions['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def one_hot_encode(caption_dictionary):\n",
    "    captions_dict = {}\n",
    "    for filename in caption_dictionary:\n",
    "        captions_dict[filename]=[]\n",
    "        for caption in caption_dictionary[filename]:\n",
    "            encoded = to_categorical(caption, num_classes=len(idx2token)+1)\n",
    "            captions_dict[filename].append(encoded)\n",
    "    return captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions_onehot = one_hot_encode(train_captions)\n",
    "dev_captions_onehot = one_hot_encode(dev_captions)\n",
    "test_captions_onehot = one_hot_encode(test_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the shape of result of one hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40000 number of captions in total.\n",
      "The maximum words in a sentence is 37\n"
     ]
    }
   ],
   "source": [
    "caption_lengths = []\n",
    "for filename in train_captions.keys():\n",
    "    for caption in train_captions[filename]:\n",
    "        caption_lengths.append(len(caption))\n",
    "for filename in dev_captions.keys():\n",
    "    for caption in dev_captions[filename]:\n",
    "        caption_lengths.append(len(caption))        \n",
    "for filename in test_captions.keys():\n",
    "    for caption in test_captions[filename]:\n",
    "        caption_lengths.append(len(caption))\n",
    "\n",
    "max_words_in_sentence = max(caption_lengths)\n",
    "\n",
    "print(\"There are {} number of captions in total.\".format(len(caption_lengths)))\n",
    "print(\"The maximum words in a sentence is {}\".format(max_words_in_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2530 distinct words in captions\n",
      "Thera are 30000 captions in training set\n",
      "(30000, 37, 2531)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = len(vocab)\n",
    "num_captions_per_image = 5 # 5 stands for number of captions per image\n",
    "total_captions = len(train_captions) * num_captions_per_image \n",
    "print(\"There are {} distinct words in captions\".format(num_words))\n",
    "print(\"Thera are {} captions in training set\".format(total_captions))\n",
    "\n",
    "train_captions_onehot_processed = np.zeros((total_captions, max_words_in_sentence, num_words+1)).astype(bool)\n",
    "print(train_captions_onehot_processed.shape)\n",
    "\n",
    "for i, filename in enumerate(train_fns_list):\n",
    "    for j, caption in enumerate(train_captions_onehot[filename]):\n",
    "        for k, onehot in enumerate(caption):\n",
    "            train_captions_onehot_processed[i*num_captions_per_image + j][k] = onehot\n",
    "            \n",
    "# Checking if train_captions_onehot_processed is correctly implemented\n",
    "# Checking if number of words are identical per caption\n",
    "Check_word_lengths = []\n",
    "for i in range(len(train_captions)):\n",
    "    for j in range(num_captions_per_image):\n",
    "        Check_word_lengths.append(train_captions_onehot_processed[i*num_captions_per_image + j].sum() == len(train_captions[train_fns_list[i]][j]))\n",
    "\n",
    "print(sum(Check_word_lengths) == total_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2530 distinct words in captions\n",
      "Thera are 5000 captions in validation set\n",
      "(5000, 37, 2531)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "num_words = len(vocab)\n",
    "num_captions_per_image = 5 # 5 stands for number of captions per image\n",
    "total_captions = len(dev_captions) * num_captions_per_image \n",
    "print(\"There are {} distinct words in captions\".format(num_words))\n",
    "print(\"Thera are {} captions in validation set\".format(total_captions))\n",
    "\n",
    "dev_captions_onehot_processed = np.zeros((total_captions, max_words_in_sentence, num_words+1)).astype(bool)\n",
    "print(dev_captions_onehot_processed.shape)\n",
    "\n",
    "for i, filename in enumerate(dev_fns_list):\n",
    "    for j, caption in enumerate(dev_captions_onehot[filename]):\n",
    "        for k, onehot in enumerate(caption):\n",
    "            dev_captions_onehot_processed[i*num_captions_per_image + j][k] = onehot\n",
    "            \n",
    "# Checking if dev_captions_onehot_processed is correctly implemented\n",
    "# Checking if number of words are identical per caption\n",
    "Check_word_lengths = []\n",
    "for i in range(len(dev_captions)):\n",
    "    for j in range(num_captions_per_image):\n",
    "        Check_word_lengths.append(dev_captions_onehot_processed[i*num_captions_per_image + j].sum() == len(dev_captions[dev_fns_list[i]][j]))\n",
    "\n",
    "print(sum(Check_word_lengths) == total_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2530 distinct words in captions\n",
      "Thera are 5000 captions in test set\n",
      "(5000, 37, 2531)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "num_words = len(vocab)\n",
    "num_captions_per_image = 5 # 5 stands for number of captions per image\n",
    "total_captions = len(test_captions) * num_captions_per_image \n",
    "print(\"There are {} distinct words in captions\".format(num_words))\n",
    "print(\"Thera are {} captions in test set\".format(total_captions))\n",
    "\n",
    "test_captions_onehot_processed = np.zeros((total_captions, max_words_in_sentence, num_words+1)).astype(bool)\n",
    "print(test_captions_onehot_processed.shape)\n",
    "\n",
    "for i, filename in enumerate(test_fns_list):\n",
    "    for j, caption in enumerate(test_captions_onehot[filename]):\n",
    "        for k, onehot in enumerate(caption):\n",
    "            test_captions_onehot_processed[i*num_captions_per_image + j][k] = onehot\n",
    "            \n",
    "# Checking if test_captions_onehot_processed is correctly implemented\n",
    "# Checking if number of words are identical per caption\n",
    "Check_word_lengths = []\n",
    "for i in range(len(test_captions)):\n",
    "    for j in range(num_captions_per_image):\n",
    "        Check_word_lengths.append(test_captions_onehot_processed[i*num_captions_per_image + j].sum() == len(test_captions[test_fns_list[i]][j]))\n",
    "\n",
    "print(sum(Check_word_lengths) == total_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('preprocessed_captions/Flicker8k_onehot_2530_words',\n",
    "        train=train_captions_onehot_processed,\n",
    "        test=test_captions_onehot_processed,\n",
    "        validation=dev_captions_onehot_processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
