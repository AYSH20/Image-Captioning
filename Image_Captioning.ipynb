{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.load('train_dev_test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_output = all_data['train_encoder_output']\n",
    "train_decoder_input = all_data['train_decoder_input']\n",
    "train_decoder_target = all_data['train_decoder_target']\n",
    "validation_encoder_output = all_data['validation_encoder_output']\n",
    "validation_decoder_input = all_data['validation_decoder_input']\n",
    "validation_decoder_target = all_data['validation_decoder_target']\n",
    "test_encoder_output = all_data['test_encoder_output']\n",
    "test_decoder_input = all_data['test_decoder_input']\n",
    "test_decoder_target = all_data['test_decoder_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caption_utils import *\n",
    "train_fns_list, dev_fns_list, test_fns_list = load_split_lists()\n",
    "\n",
    "train_captions_raw, dev_captions_raw, test_captions_raw = get_caption_split()\n",
    "vocab = create_vocab(train_captions_raw)\n",
    "token2idx, idx2token = vocab_to_index(vocab)    \n",
    "captions_data = (train_captions_raw.copy(), dev_captions_raw.copy(), test_captions_raw.copy())\n",
    "train_captions, dev_captions, test_captions = process_captions(captions_data, token2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, RepeatVector, Concatenate, Merge, Masking\n",
    "from keras.layers import LSTM, GRU, Embedding, TimeDistributed, Bidirectional\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 300\n",
    "lstm_size = 300\n",
    "vocab_size = len(vocab)\n",
    "max_length = train_decoder_target.shape[1]\n",
    "\n",
    "lr = 0.001\n",
    "dropout_rate = 0.2\n",
    "batch_size = 64\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input shape (?, 512)\n",
      "(?, 1, 300)\n"
     ]
    }
   ],
   "source": [
    "# Image -> Image embedding\n",
    "image_input = Input(shape=(train_encoder_output.shape[1], ), name='image_input')\n",
    "print(\"Image Input shape\", image_input.shape)\n",
    "img_emb = Dense(emb_size, activation='relu')(image_input)\n",
    "img_emb = RepeatVector(1)(img_emb)\n",
    "print(img_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption Input Shape (?, ?)\n",
      "(?, ?, 300)\n"
     ]
    }
   ],
   "source": [
    "# Sentence to Word embedding\n",
    "caption_inputs = Input(shape=(None, ), name='caption_input')\n",
    "print(\"Caption Input Shape\", caption_inputs.shape)\n",
    "word_emb = Embedding(input_dim=vocab_size, output_dim=emb_size)(caption_inputs)\n",
    "print(word_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 300)\n"
     ]
    }
   ],
   "source": [
    "# Merge img_emb and word_emb\n",
    "seq_input = Concatenate(axis=1)([img_emb, word_emb])\n",
    "seq_input = BatchNormalization()(seq_input)\n",
    "seq_input = Masking(mask_value=0., input_shape=(None, emb_size))(seq_input)\n",
    "print(seq_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 2531)\n"
     ]
    }
   ],
   "source": [
    "# Sequence to Sequence\n",
    "gru_cell = Bidirectional(LSTM(lstm_size, return_sequences=True))(seq_input)\n",
    "gru_cell = BatchNormalization()(gru_cell)\n",
    "seq_out = TimeDistributed(Dense(vocab_size, activation='softmax'))(gru_cell)\n",
    "\n",
    "print(seq_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[image_input,caption_inputs], outputs=[seq_out])\n",
    "\n",
    "model.compile(optimizer=rmsprop,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 512)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          153900      image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "caption_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 1, 300)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    759300      caption_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 300)    0           repeat_vector_1[0][0]            \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 300)    1200        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 300)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 600)    1442400     masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 600)    2400        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 2531)   1521131     batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 3,880,331\n",
      "Trainable params: 3,878,531\n",
      "Non-trainable params: 1,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 4.6461e-07 - acc: 0.2949\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.9909e-07 - acc: 0.2949\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.0587e-07 - acc: 0.2949\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.8263e-07 - acc: 0.2949\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.6002e-07 - acc: 0.2949\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.4489e-07 - acc: 0.2949\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.3281e-07 - acc: 0.2949\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.2379e-07 - acc: 0.2949\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.1661e-07 - acc: 0.2949\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.1019e-07 - acc: 0.2949\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0408e-07 - acc: 0.2949\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0011e-07 - acc: 0.2949\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 9.3992e-08 - acc: 0.2949\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 9.2616e-08 - acc: 0.2949\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 8.9101e-08 - acc: 0.2949\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 8.3752e-08 - acc: 0.2949\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 8.2071e-08 - acc: 0.2949\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.8403e-08 - acc: 0.2949\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.7028e-08 - acc: 0.2949\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.3207e-08 - acc: 0.2949\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.1067e-08 - acc: 0.2949\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.9539e-08 - acc: 0.2949\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.7399e-08 - acc: 0.2949\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.4495e-08 - acc: 0.2949\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.2967e-08 - acc: 0.2949\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.1133e-08 - acc: 0.2949\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.9452e-08 - acc: 0.2949\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.8993e-08 - acc: 0.2949\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.6701e-08 - acc: 0.2949\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.5631e-08 - acc: 0.2949\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.4561e-08 - acc: 0.2949\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.3950e-08 - acc: 0.2949\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.2574e-08 - acc: 0.2949\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.1505e-08 - acc: 0.2949\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.9976e-08 - acc: 0.2949\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.9823e-08 - acc: 0.2949\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.8142e-08 - acc: 0.2949\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.8448e-08 - acc: 0.2949\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.7225e-08 - acc: 0.2949\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.6461e-08 - acc: 0.2949\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.6767e-08 - acc: 0.2949\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.5850e-08 - acc: 0.2949\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.5391e-08 - acc: 0.2949\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.5238e-08 - acc: 0.2949\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.4016e-08 - acc: 0.2949\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.3863e-08 - acc: 0.2949\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.3557e-08 - acc: 0.2949\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.2640e-08 - acc: 0.2949\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.2335e-08 - acc: 0.2949\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.1723e-08 - acc: 0.2949\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.1418e-08 - acc: 0.2949\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.0348e-08 - acc: 0.2949\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.1112e-08 - acc: 0.2949\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.0195e-08 - acc: 0.2949\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.0501e-08 - acc: 0.2949\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.0501e-08 - acc: 0.2949\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.9889e-08 - acc: 0.2949\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.9736e-08 - acc: 0.2949\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.8667e-08 - acc: 0.2949\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.8819e-08 - acc: 0.2949\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.8361e-08 - acc: 0.2949\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.8972e-08 - acc: 0.2949\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.8208e-08 - acc: 0.2949\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.8055e-08 - acc: 0.2949\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7597e-08 - acc: 0.2949\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7750e-08 - acc: 0.2949\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7750e-08 - acc: 0.2949\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7750e-08 - acc: 0.2949\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7444e-08 - acc: 0.2949\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6527e-08 - acc: 0.2949\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6833e-08 - acc: 0.2949\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6527e-08 - acc: 0.2949\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6680e-08 - acc: 0.2949\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6680e-08 - acc: 0.2949\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7291e-08 - acc: 0.2949\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6221e-08 - acc: 0.2949\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6374e-08 - acc: 0.2949\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6374e-08 - acc: 0.2949\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6221e-08 - acc: 0.2949\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6374e-08 - acc: 0.2949\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6985e-08 - acc: 0.2949\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6833e-08 - acc: 0.2949\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6527e-08 - acc: 0.2949\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5151e-08 - acc: 0.2949\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5916e-08 - acc: 0.2949\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5763e-08 - acc: 0.2949\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5151e-08 - acc: 0.2949\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.6068e-08 - acc: 0.2949\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5151e-08 - acc: 0.2949\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5763e-08 - acc: 0.2949\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5763e-08 - acc: 0.2949\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.5457e-08 - acc: 0.2949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7aefe902e8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_encoder_output[:10,:], train_decoder_input[:10,:]], [train_decoder_target[:10,:,:]], \n",
    "#           validation_data=([validation_encoder_output, validation_decoder_input], [validation_decoder_target]),\n",
    "           epochs=100, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_seq(encoder_output):\n",
    "    generated_sentence = []\n",
    "    start, end = token2idx['<bos>'], token2idx['<eos>']\n",
    "    current = start\n",
    "    while len(generated_sentence) < 20:\n",
    "        X = [encoder_output.reshape(1, 512), np.array([current])]\n",
    "        \n",
    "        predicted = model.predict(X)\n",
    "        \n",
    "        current = np.argmax(predicted, axis=-1)[0][1]\n",
    "        \n",
    "        if current == end:\n",
    "            break\n",
    "        generated_sentence.append(idx2token[current])\n",
    "            \n",
    "    return ' '.join(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two dogs <bos> two dogs <bos> two dogs <bos> two dogs <bos> two dogs <bos> two dogs <bos> two dogs 20\n",
      "the <bos> the <bos> the <bos> the <bos> the <bos> the <bos> the <bos> the <bos> the <bos> the <bos> 20\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10, 5):\n",
    "    res = _generate_seq(train_encoder_output[i, :])\n",
    "    print(res, len(res.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> a black dog is running after a white dog in the snow <eos>\n",
      "<bos> black dog chasing brown dog through snow <eos>\n",
      "<bos> two dogs chase each other across the snowy ground <eos>\n",
      "<bos> two dogs play together in the snow <eos>\n",
      "<bos> two dogs running through a low lying body of water <eos>\n",
      "<bos> a little baby plays croquet <eos>\n",
      "<bos> a little girl plays croquet next to a truck <eos>\n",
      "<bos> the child is playing <unk> by the truck <eos>\n",
      "<bos> the kid is in front of a car with a put and a ball <eos>\n",
      "<bos> the little boy is playing with a croquet <unk> and ball beside the car <eos>\n",
      "<bos> a brown dog in the snow has something hot pink in its mouth <eos>\n",
      "<bos> a brown dog in the snow holding a pink hat <eos>\n",
      "<bos> a brown dog is holding a pink shirt in the snow <eos>\n",
      "<bos> a dog is carrying something pink in its mouth while walking through the snow <eos>\n",
      "<bos> a dog with something pink in its mouth is looking forward <eos>\n",
      "<bos> a brown dog is running along a beach <eos>\n",
      "<bos> a brown dog wearing a black collar running across the beach <eos>\n",
      "<bos> a dog walks on the sand near the water <eos>\n",
      "<bos> brown dog running on the beach <eos>\n",
      "<bos> the large brown dog is running on the beach by the ocean <eos>\n",
      "<bos> a black and white dog with a red frisbee standing on a sandy beach <eos>\n",
      "<bos> a dog <unk> a red disc on a beach <eos>\n",
      "<bos> a dog with a red frisbee flying in the air <eos>\n",
      "<bos> dog catching a red frisbee <eos>\n",
      "<bos> the black dog is dropping a red disc on a beach <eos>\n",
      "<bos> a cyclist wearing a red helmet is riding on the pavement <eos>\n",
      "<bos> a girl is riding a bike on the street while wearing a red helmet <eos>\n",
      "<bos> a person on a bike wearing a red helmet riding down a street <eos>\n",
      "<bos> a woman wears a red helmet and blue shirt as she goes for a bike ride in the shade <eos>\n",
      "<bos> person in blue shirt and red helmet riding bike down the road <eos>\n",
      "<bos> a man dressed in a purple shirt and red bandanna smiles at the people watching him <eos>\n",
      "<bos> a man on the street wearing leather <unk> and a <unk> <unk> <eos>\n",
      "<bos> a man wearing a purple shirt and black leather <unk> poses for the camera <eos>\n",
      "<bos> man dressed in leather <unk> and purple shirt stands in front of onlookers <eos>\n",
      "<bos> there is a man in a purple shirt leather <unk> and a red bandanna standing near other men <eos>\n",
      "<bos> a boy wearing a red t shirt is running through woodland <eos>\n",
      "<bos> a child runs near some trees <eos>\n",
      "<bos> a young boy is dancing around <eos>\n",
      "<bos> a young boy with a red short sleeved shirt and jeans runs by some trees <eos>\n",
      "<bos> the little boy in the red shirt stops to smile for the camera <eos>\n",
      "<bos> a girl in a white dress <eos>\n",
      "<bos> a little girl in white is looking back at the camera while carrying a water <unk> <eos>\n",
      "<bos> a smiling young girl in <unk> is playing ball <eos>\n",
      "<bos> a young girl wearing white looks at the camera as she plays <eos>\n",
      "<bos> the girl is holding a green ball <eos>\n",
      "<bos> a skier in a yellow jacket is airborne above the mountains <eos>\n",
      "<bos> a skier jumps high in the air with a view of the mountains <eos>\n",
      "<bos> a skiing man in a <unk> jacket jumps very high and it looks as though he is flying <eos>\n",
      "<bos> <unk> is high in the air doing a ski jump <eos>\n",
      "<bos> the skier in the green jacket and white pants appears to almost fly into the sky <eos>\n",
      "<bos> a photographer looks over the hills <eos>\n",
      "<bos> a woman in a red jacket is <unk> a natural landscape <eos>\n",
      "<bos> a woman with a camera looks out over rolling hills <eos>\n",
      "<bos> a woman with a camera on a tripod is looking at the view <eos>\n",
      "<bos> lady in red shirt has her camera set up in the field to record something <eos>\n",
      "<bos> a bunch of girls in cheerleader outfits <eos>\n",
      "<bos> a large group of cheerleaders walking in a parade <eos>\n",
      "<bos> cheerleaders perform <eos>\n",
      "<bos> many cheerleaders wearing black walk down the street <eos>\n",
      "<bos> parade of cheerleaders wearing black pink and white uniforms <eos>\n",
      "<bos> a blue boat with a yellow canopy is floating on calm waters <eos>\n",
      "<bos> a boat in the water <eos>\n",
      "<bos> a boat with a roof on green water <eos>\n",
      "<bos> the boat is in the middle of the water <eos>\n",
      "<bos> the <unk> boat floats on the lake <eos>\n",
      "<bos> a dog catches a frisbee in midair <eos>\n",
      "<bos> a dog catching a frisbee <eos>\n",
      "<bos> a terrier <unk> catches a frisbee in the air <eos>\n",
      "<bos> a white and black dog catching a frisbee <eos>\n",
      "<bos> a white dog is leaping in the air with a green object in its mouth <eos>\n",
      "<bos> a little old lady sitting next to an advertisement <eos>\n",
      "<bos> an asian woman waiting at an <unk> train stop <eos>\n",
      "<bos> an old woman sits in a <unk> station next to a backlit advertisement <eos>\n",
      "<bos> a woman sits in a subway station <eos>\n",
      "<bos> a woman with an umbrella is sitting at a station with an <unk> <unk> on the wall <eos>\n",
      "<bos> a blond girl wearing a green jacket walks on a trail along side a metal fence <eos>\n",
      "<bos> a girl in a green coat walks down a rural road playing a flute <eos>\n",
      "<bos> a young girl in a parka playing a flute while walking by a fenced in field <eos>\n",
      "<bos> girl in green and blue jacket walking past an enclosed field <eos>\n",
      "<bos> girl playing flute as she walks by fence in rural area <eos>\n",
      "<bos> a family of <unk> people including four children pose in front of a brick fireplace with a white <unk> <eos>\n",
      "<bos> a family poses in front of the fireplace and christmas tree <eos>\n",
      "<bos> a family posing by the <unk> and christmas tree <eos>\n",
      "<bos> a happy family poses by the fireplace <eos>\n",
      "<bos> two couples and four kids pose for a family picture <eos>\n",
      "<bos> man in a sweater pointing at the camera <eos>\n",
      "<bos> one man is posing with arms outstretched and finger pointed while another stares from behind him <eos>\n",
      "<bos> the man in the black hat stands behind the man who is pointing his finger <eos>\n",
      "<bos> two men look toward the camera while the one in front points his <unk> finger <eos>\n",
      "<bos> two men one wearing a black hat while the one in front points standing in a hallway <eos>\n",
      "<bos> a dog looks <unk> at the brown dog <unk> his area <eos>\n",
      "<bos> a large brown dog is looking at a medium sized black dog <eos>\n",
      "<bos> a small black dog looks at a larger brown dog in a grassy field <eos>\n",
      "<bos> the big brown dog looks at the small black dog in tall grass <eos>\n",
      "<bos> there is a big dog looking at a little dog <eos>\n",
      "<bos> three children in a field with white flowers <eos>\n",
      "<bos> three children one with a stuffed <unk> in a field of flowers <eos>\n",
      "<bos> three children play in the garden <eos>\n",
      "<bos> three children pose among <unk> <eos>\n",
      "<bos> three kids <unk> with a toy cat in a garden <eos>\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    for j in range(5):\n",
    "        print(intseq_to_caption(idx2token, train_captions[train_fns_list[i]][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
